# -*- coding: utf-8 -*-
"""trainDraw.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AFzIxxSE8-5YijwGB6SGohgRTMKbAyBS
"""

import os
import urllib.request
import ssl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from keras import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.regularizers import l2
from keras.utils import to_categorical
from sklearn.metrics import confusion_matrix, classification_report

# Disable SSL verification for urllib
ssl._create_default_https_context = ssl._create_unverified_context

# Set your class labels
CLASSES = ['cat', 'diamond', 'eye', 'ladder', 'moon', 'necklace', 'snowflake', 'sword', 'tornado', 'watermelon']
DATASET_DIR = './dataset'
SAMPLES_PER_CLASS = 20000
IMG_SIZE = 28

def download_quickdraw_data(classes):
    base_url = "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/"
    os.makedirs(DATASET_DIR, exist_ok=True)

    for cls in classes:
        file_path = os.path.join(DATASET_DIR, f'full_numpy_bitmap_{cls}.npy')
        if not os.path.exists(file_path):
            print(f"Downloading: {cls}")
            cls_url = base_url + cls.replace('_', '%20') + '.npy'
            urllib.request.urlretrieve(cls_url, file_path)
        else:
            print(f"{cls} already downloaded.")

# Load and preprocess data
def load_data(classes, samples_per_class, test_split=0.2):
    download_quickdraw_data(classes)

    train_data, train_labels = [], []
    test_data, test_labels = [], []

    for label_index, cls in enumerate(classes):
        path = os.path.join(DATASET_DIR, f'full_numpy_bitmap_{cls}.npy')
        data = np.load(path)[:samples_per_class]
        split_idx = int(len(data) * (1 - test_split))

        train_data.append(data[:split_idx])
        train_labels += [label_index] * split_idx

        test_data.append(data[split_idx:])
        test_labels += [label_index] * (len(data) - split_idx)

    train_data = np.concatenate(train_data).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0
    test_data = np.concatenate(test_data).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0
    train_labels_cat = to_categorical(np.array(train_labels), num_classes=len(classes))
    test_labels_cat = to_categorical(np.array(test_labels), num_classes=len(classes))

    return train_data, train_labels_cat, test_data, test_labels_cat, train_labels, test_labels

# Build the CNN model
def build_model(input_shape, num_classes):
    model = Sequential([
        Conv2D(16, (5, 5), padding='same', activation='relu', input_shape=input_shape),
        Conv2D(16, (5, 5), padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.25),

        Conv2D(16, (5, 5), padding='same', activation='relu'),
        Conv2D(32, (5, 5), padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.25),

        Conv2D(32, (5, 5), padding='same', activation='relu'),
        Conv2D(64, (5, 5), padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.25),

        Conv2D(64, (3, 3), padding='same', activation='relu'),
        Conv2D(128, (3, 3), padding='same', activation='relu'),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.5),
        Flatten(),

        Dense(128, activation="relu", kernel_regularizer=l2(0.01)),
        Dense(256, activation="relu", kernel_regularizer=l2(0.01)),
        Dense(num_classes, activation="softmax")
    ])
    model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
    return model

# Load data
train_data, train_labels_cat, test_data, test_labels_cat, train_labels, test_labels = load_data(CLASSES, SAMPLES_PER_CLASS)

# Build model
model = build_model((IMG_SIZE, IMG_SIZE, 1), len(CLASSES))
model.summary()

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels_cat, test_size=0.2, random_state=42)

history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=200)

# Evaluate
_, train_acc = model.evaluate(train_data, train_labels_cat)
print(f"Train Accuracy: {train_acc:.2f}")

_, test_acc = model.evaluate(test_data, test_labels_cat)
print(f"Test Accuracy: {test_acc:.2f}")

model.save("QuickDrawCNN.h5")
print("Model saved as QuickDrawCNN.h5")

model.save("QuickDrawCNN.keras")
print("Model saved as QuickDrawCNN.keras")

# Plot accuracy
plt.plot(history.history["accuracy"], label="Train Acc")
plt.plot(history.history["val_accuracy"], label="Val Acc")
plt.title("Accuracy over Epochs")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.grid()
plt.show()

# Plotting Training and Validation Loss
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)

plt.figure(figsize=(6, 4))
plt.plot(epochs, loss, 'b-', label='Train Loss')
plt.plot(epochs, val_loss, 'r--', label='Val Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# CONFUSION MATRIX PLOT
print("\nGenerating Confusion Matrix...")

# Predict and decode class labels
y_pred = np.argmax(model.predict(test_data), axis=1)
y_true = np.array(test_labels)

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=CLASSES, yticklabels=CLASSES)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

#  Print detailed classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=CLASSES))

import matplotlib.pyplot as plt
import numpy as np

# Predict a random sample
index = np.random.randint(0, len(test_data))
sample = test_data[index].reshape(1, 28, 28, 1)  # Reshape for prediction

prediction = model.predict(sample)
predicted_class = np.argmax(prediction)

true_class = np.argmax(test_labels_cat[index])

print(f"True Label: {CLASSES[true_class]}")
print(f"Predicted Label: {CLASSES[predicted_class]}")

# Show the image
plt.imshow(sample[0, :, :, 0], cmap='gray')
plt.title(f"Predicted: {CLASSES[predicted_class]}")
plt.axis('off')
plt.show()

from keras.models import load_model

# Load model
model = load_model('QuickDrawCNN.h5')

# Evaluate on test set
test_loss, test_acc = model.evaluate(test_data, test_labels_cat, verbose=1)
print(f"Test Accuracy: {test_acc:.2f}")

